fnr.res = vector(length = dim(data.test)[1])
precision.res = vector(length = dim(data.test)[1])
accuracy.res = vector(length = dim(data.test)[1])
for (i in (1:dim(data.test)[1])) {
m = MEASURE$new(target <- y.test[,i], prediction <- svm.res[i,])
print (target)
print (round(as.numeric(prediction), 3))
threshold = 0.625
tpr.res[i] <- m$truePositiveRate(threshold)
tnr.res[i] <- m$trueNegativeRate(threshold)
fpr.res[i] <- m$falsePositiveRate(threshold)
fnr.res[i] <- m$falseNegativeRate(threshold)
precision.res[i] <- m$precision(threshold)
accuracy.res[i] <- m$accuracy(threshold)
}
tpr.res = vector(length = dim(data.test)[1])
tnr.res = vector(length = dim(data.test)[1])
fpr.res = vector(length = dim(data.test)[1])
fnr.res = vector(length = dim(data.test)[1])
precision.res = vector(length = dim(data.test)[1])
accuracy.res = vector(length = dim(data.test)[1])
for (i in (1:dim(data.test)[1])) {
m = MEASURE$new(target <- y.test[,i], prediction <- svm.res[i,])
print (data.frame(t = target, p = round(as.numeric(prediction), 3)))
threshold = 0.625
tpr.res[i] <- m$truePositiveRate(threshold)
tnr.res[i] <- m$trueNegativeRate(threshold)
fpr.res[i] <- m$falsePositiveRate(threshold)
fnr.res[i] <- m$falseNegativeRate(threshold)
precision.res[i] <- m$precision(threshold)
accuracy.res[i] <- m$accuracy(threshold)
}
source('~/Documents/studia/sus/sus/knn.R')
library(FactoRizationMachines)
?SVM.train
?predict
?SVM.train
c(1,2,3) <- 0
recommendedEventsWithPred <- function (target, pred, threshold) {
tp <- data.frame(t = target, p = pred, event = 1:length(target))
tp <- tp[tp$t == 0 & abs(tp$p) > threshold,]
return (rec)
}
recommendedEventsWithPred(c(0,0,1,1), c(0.65, 0.025, 1, 1), 0.5)
recommendedEventsWithPred <- function (target, pred, threshold) {
tp <- data.frame(t = target, p = pred, event = 1:length(target))
tp <- tp[tp$t == 0 & abs(tp$p) > threshold,]
return (tp)
}
recommendedEventsWithPred(c(0,0,1,1), c(0.65, 0.025, 1, 1), 0.5)
recommendedEventsWithPred <- function (target, pred, threshold) {
tp <- data.frame(t = target, p = pred, event = 1:length(target))
rec <- as.numeric(pred)
tp <- tp[tp$t == 0 & abs(tp$p) > threshold,]
rec[-tp$event] <- 0
return (tp)
}
recommendedEventsWithPred(c(0,0,1,1), c(0.65, 0.025, 1, 1), 0.5)
recommendedEventsWithPred <- function (target, pred, threshold) {
tp <- data.frame(t = target, p = pred, event = 1:length(target))
rec <- as.numeric(pred)
tp <- tp[tp$t == 0 & abs(tp$p) > threshold,]
rec[-tp$event] <- 0
return (rec)
}
recommendedEventsWithPred(c(0,0,1,1), c(0.65, 0.025, 1, 1), 0.5)
recommendedEventsWithPred(c(0,0,1,1,0), c(0.65, 0.025, 1, 1, 0.51), 0.5)
recommendedEventsWithPred(c(0,0,1,1,0), c(0.65, 0.025, 1, 1, -0.51), 0.5)
getVectorOfClassifiedEvents(c(0,0,1,1,0), c(0.65, 0.025, 1, 1, -0.51), 0.5)
getVectorOfClassifiedEvents <- function (target, pred, threshold) {
tp <- data.frame(t = target, p = pred, event = 1:length(target))
rec <- as.numeric(vector(length = length(target)))
tp <- tp[tp$t == 0 & abs(tp$p) > threshold,]
rec[tp$event] <- 1
return (rec)
}
#' @return Vector of events that are marked as recommended.
#' @export
getRecommendedEvents <- function (target, pred, threshold) {
tp <- data.frame(t = target, p = pred, event = 1:length(target))
tp <- tp[tp$t == 0 & abs(tp$p) > threshold,]
return (tp$event)
}
#' @return Vector of 0/x (where x is prediction of event) depending on event is recommended or not.
#' @export
recommendedEventsWithPred <- function (target, pred, threshold) {
tp <- data.frame(t = target, p = pred, event = 1:length(target))
rec <- as.numeric(pred)
tp <- tp[tp$t == 0 & abs(tp$p) > threshold,]
rec[-tp$event] <- 0
return (rec)
}
getVectorOfClassifiedEvents(c(0,0,1,1,0), c(0.65, 0.025, 1, 1, -0.51), 0.5)
source('~/Documents/studia/sus/sus/lab6.R')
AMORE::predict
predict
?predict
nnetModel = neuralnet(setosa+versicolor+virginica ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=data.iris.train, hidden=c(3))
library(neuralnet)
nnetModel = neuralnet(setosa+versicolor+virginica ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=data.iris.train, hidden=c(3))
plot(nnetModel)
nnetModel = neuralnet(setosa+versicolor+virginica ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=data.iris.train, hidden=c(5))
plot(nnetModel)
nnetModel = neuralnet(setosa+versicolor+virginica ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=data.iris.train, hidden=c(5), stepmax = 100)
nnetModel = neuralnet(setosa+versicolor+virginica ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=data.iris.train, hidden=c(5), stepmax = 1000)
nnetModel = neuralnet(setosa+versicolor+virginica ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=data.iris.train, hidden=c(5), stepmax = 10000)
nnetModel = neuralnet(setosa+versicolor+virginica ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=data.iris.train, hidden=c(4), stepmax = 10000)
nnetModel = neuralnet(setosa+versicolor+virginica ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
data=data.iris.train, hidden=c(3))
plot(nnetModel)
?compute
predict(nnetModel, data.iris.test[,1:4])
library(nnet)
?nnet
nnetModel = nnet(setosa+versicolor+virginica ~ Sepal.Length+Sepal.Width+Petal.Length+Petal.Width,
x = data.iris.train[,1:4], y = data.iris.train[,6:8], size = 3)
nnetModel = nnet(data.iris.train[,1:4], data.iris.train[,6:8], size = 3)
plot(nnetModel)
predict(nnetModel, data.iris.test[,1:4])
?max.col
preds = predict(nnetModel, data.iris.test[,1:4])
max.col(preds)
subset = sample(dim(iris)[1], size = dim(iris)[1] * 0.8, replace = F)
data.iris = iris
data.iris = cbind(data.iris, setosa = as.numeric(iris$Species == 'setosa'))
data.iris = cbind(data.iris, versicolor = as.numeric(iris$Species == 'versicolor'))
data.iris = cbind(data.iris, virginica = as.numeric(iris$Species == 'virginica'))
data.iris.train = data.iris[subset,]
data.iris.test = data.iris[-subset,]
myNNet = newff(n.neurons = c(4,10,3), learning.rate.global = 0.4, momentum.global = 0.3,
error.criterium = "LMS", Stao=NA, hidden.layer = "sigmoid", output.layer = "sigmoid")
myNNetModel = train(myNNet, data.iris.train[,1:4], data.iris.train[,6:8], report=F, n.shows = 10, show.step = 100)
predict(myNNetModel, data.iris.test[,1:4])
library(ROCR)
ROCR::prediction(myNNetModel, data.iris.test[,1:4])
sim.MLPnet(myNNetModel$net)
?sim.MLPnet
sim.MLPnet(myNNetModel$net, data.iris.test[,1:4])
ROCR::prediction(sim.MLPnet(myNNetModel$net, data.iris.test[,1:4]))
ROCR::prediction(sim.MLPnet(myNNetModel$net, data.iris.test[,1:4]), data.iris.test[,6:8])
sim.MLPnet(myNNetModel$net, data.iris.test[,1:4])
scores = sim.MLPnet(myNNetModel$net, data.iris.test[,1:4])
scores
max.col(scores)
max.col(data.iris.test[,6:8])
data.iris.test[,6:8]
table(max.col(scores), max.col(data.iris.test[,6:8]))
subset = sample(dim(iris)[1], size = dim(iris)[1] * 0.8, replace = F)
data.iris = iris
iris.species = c('setosa', 'versicolor', 'virginica')
data.iris = cbind(data.iris, setosa = as.numeric(iris$Species == iris.species[1]))
data.iris = cbind(data.iris, versicolor = as.numeric(iris$Species == iris.species[2]))
data.iris = cbind(data.iris, virginica = as.numeric(iris$Species == iris.species[3]))
data.iris.train = data.iris[subset,]
data.iris.test = data.iris[-subset,]
myNNet = newff(n.neurons = c(4,10,3), learning.rate.global = 0.4, momentum.global = 0.3,
error.criterium = "LMS", Stao=NA, hidden.layer = "sigmoid", output.layer = "sigmoid")
myNNetModel = train(myNNet, data.iris.train[,1:4], data.iris.train[,6:8], report=F, n.shows = 10, show.step = 100)
scores = sim.MLPnet(myNNetModel$net, data.iris.test[,1:4])
res = table(max.col(scores), max.col(data.iris.test[,6:8]))
row.names(res) = iris.species
colnames(res) = iris.species
iris.species
res
acc = sum(diag(res)) / 3
print (paste("accuracy", acc))
acc = sum(diag(res)) / dim(data.iris.test)[1]
print (paste("accuracy", acc))
dim(data.iris.test)[1]
sum(diag(res))
acc = sum(diag(res)) / dim(data.iris.test)[1]
print (paste("accuracy", acc))
myNNet = newff(n.neurons = c(4,10,3), learning.rate.global = 0.4, momentum.global = 0.2,
error.criterium = "LMS", Stao=NA, hidden.layer = "sigmoid", output.layer = "sigmoid")
myNNetModel = train(myNNet, data.iris.train[,1:4], data.iris.train[,6:8], report=F, n.shows = 10, show.step = 100)
scores = sim.MLPnet(myNNetModel$net, data.iris.test[,1:4])
res = table(max.col(scores), max.col(data.iris.test[,6:8]))
row.names(res) = iris.species
colnames(res) = iris.species
acc = sum(diag(res)) / dim(data.iris.test)[1]
print (paste("accuracy", acc))
myNNet = newff(n.neurons = c(4,10,3), learning.rate.global = 0.4, momentum.global = 0.2,
error.criterium = "LMS", Stao=NA, hidden.layer = "sigmoid", output.layer = "sigmoid")
myNNetModel = train(myNNet, data.iris.train[,1:4], data.iris.train[,6:8], report=F, n.shows = 10, show.step = 100)
scores = sim.MLPnet(myNNetModel$net, data.iris.test[,1:4])
res = table(max.col(scores), max.col(data.iris.test[,6:8]))
row.names(res) = iris.species
colnames(res) = iris.species
acc = sum(diag(res)) / dim(data.iris.test)[1]
print (paste("accuracy", acc))
myNNetModel = train(myNNet, data.iris.train[,1:4], data.iris.train[,6:8], report=F, n.shows = 100, show.step = 100)
scores = sim.MLPnet(myNNetModel$net, data.iris.test[,1:4])
res = table(max.col(scores), max.col(data.iris.test[,6:8]))
row.names(res) = iris.species
colnames(res) = iris.species
acc = sum(diag(res)) / dim(data.iris.test)[1]
print (paste("accuracy", acc))
res
myNNet = newff(n.neurons = c(4,10,3), learning.rate.global = 0.2, momentum.global = 0.2,
error.criterium = "LMS", Stao=NA, hidden.layer = "sigmoid", output.layer = "sigmoid")
myNNetModel = train(myNNet, data.iris.train[,1:4], data.iris.train[,6:8], report=F, n.shows = 100, show.step = 100)
scores = sim.MLPnet(myNNetModel$net, data.iris.test[,1:4])
res = table(max.col(scores), max.col(data.iris.test[,6:8]))
row.names(res) = iris.species
colnames(res) = iris.species
acc = sum(diag(res)) / dim(data.iris.test)[1]
print (paste("accuracy", acc))
subset = sample(dim(iris)[1], size = dim(iris)[1] * 0.8, replace = F)
data.iris = iris
iris.species = c('setosa', 'versicolor', 'virginica')
data.iris = cbind(data.iris, setosa = as.numeric(iris$Species == iris.species[1]))
data.iris = cbind(data.iris, versicolor = as.numeric(iris$Species == iris.species[2]))
data.iris = cbind(data.iris, virginica = as.numeric(iris$Species == iris.species[3]))
data.iris.train = data.iris[subset,]
data.iris.test = data.iris[-subset,]
myNNet = newff(n.neurons = c(4,10,3), learning.rate.global = 0.2, momentum.global = 0.2,
error.criterium = "LMS", Stao=NA, hidden.layer = "sigmoid", output.layer = "sigmoid")
myNNetModel = train(myNNet, data.iris.train[,1:4], data.iris.train[,6:8], report=F, n.shows = 100, show.step = 100)
scores = sim.MLPnet(myNNetModel$net, data.iris.test[,1:4])
res = table(max.col(scores), max.col(data.iris.test[,6:8]))
row.names(res) = iris.species
colnames(res) = iris.species
acc = sum(diag(res)) / dim(data.iris.test)[1]
print (paste("accuracy", acc))
source('~/Documents/studia/sus/sus/lab6.R')
source('~/Documents/studia/sus/sus/lab6.R')
source('~/Documents/studia/sus/sus/lab6.R')
source('~/Documents/studia/sus/sus/lab6.R')
source('~/Documents/studia/sus/sus/lab6.R')
source('~/Documents/studia/sus/sus/lab6.R')
plor(myNNetModel)
plot(myNNetModel)
source('~/Documents/studia/sus/sus/lab6.R')
source('~/Documents/studia/sus/sus/lab6.R')
source('~/Documents/studia/sus/sus/lab6.R')
subset = sample(dim(iris)[1], size = dim(iris)[1] * 0.8, replace = F)
data.iris = iris
iris.species = c('setosa', 'versicolor', 'virginica')
data.iris = cbind(data.iris, setosa = as.numeric(iris$Species == iris.species[1]))
data.iris = cbind(data.iris, versicolor = as.numeric(iris$Species == iris.species[2]))
data.iris = cbind(data.iris, virginica = as.numeric(iris$Species == iris.species[3]))
data.iris.train = data.iris[subset,]
data.iris.test = data.iris[-subset,]
myNNet = newff(n.neurons = c(4,10,3), learning.rate.global = 0.4, momentum.global = 0.3,
error.criterium = "LMS", Stao=NA, hidden.layer = "sigmoid", output.layer = "sigmoid")
# Train
myNNetModel = train(myNNet, data.iris.train[,1:4], data.iris.train[,6:8], report=F, n.shows = 100, show.step = 100)
# Test
scores = sim.MLPnet(myNNetModel$net, data.iris.test[,1:4])
res = table(max.col(scores), max.col(data.iris.test[,6:8]))
row.names(res) = iris.species
colnames(res) = iris.species
acc = sum(diag(res)) / dim(data.iris.test)[1]
print (paste("zad2:", "accuracy", acc))
subset = sample(dim(iris)[1], size = dim(iris)[1] * 0.8, replace = F)
data.iris = iris
iris.species = c('setosa', 'versicolor', 'virginica')
data.iris = cbind(data.iris, setosa = as.numeric(iris$Species == iris.species[1]))
data.iris = cbind(data.iris, versicolor = as.numeric(iris$Species == iris.species[2]))
data.iris = cbind(data.iris, virginica = as.numeric(iris$Species == iris.species[3]))
data.iris.train = data.iris[subset,]
data.iris.test = data.iris[-subset,]
myNNet = newff(n.neurons = c(4,20,3), learning.rate.global = 0.4, momentum.global = 0.3,
error.criterium = "LMS", Stao=NA, hidden.layer = "sigmoid", output.layer = "sigmoid")
# Train
myNNetModel = train(myNNet, data.iris.train[,1:4], data.iris.train[,6:8], report=F, n.shows = 100, show.step = 100)
# Test
scores = sim.MLPnet(myNNetModel$net, data.iris.test[,1:4])
res = table(max.col(scores), max.col(data.iris.test[,6:8]))
row.names(res) = iris.species
colnames(res) = iris.species
acc = sum(diag(res)) / dim(data.iris.test)[1]
print (paste("zad2:", "accuracy", acc))
subset = sample(dim(iris)[1], size = dim(iris)[1] * 0.8, replace = F)
data.iris = iris
iris.species = c('setosa', 'versicolor', 'virginica')
data.iris = cbind(data.iris, setosa = as.numeric(iris$Species == iris.species[1]))
data.iris = cbind(data.iris, versicolor = as.numeric(iris$Species == iris.species[2]))
data.iris = cbind(data.iris, virginica = as.numeric(iris$Species == iris.species[3]))
data.iris.train = data.iris[subset,]
data.iris.test = data.iris[-subset,]
myNNet = newff(n.neurons = c(4,20,3), learning.rate.global = 0.4, momentum.global = 0.1,
error.criterium = "LMS", Stao=NA, hidden.layer = "sigmoid", output.layer = "sigmoid")
# Train
myNNetModel = train(myNNet, data.iris.train[,1:4], data.iris.train[,6:8], report=F, n.shows = 100, show.step = 100)
# Test
scores = sim.MLPnet(myNNetModel$net, data.iris.test[,1:4])
res = table(max.col(scores), max.col(data.iris.test[,6:8]))
row.names(res) = iris.species
colnames(res) = iris.species
acc = sum(diag(res)) / dim(data.iris.test)[1]
print (paste("zad2:", "accuracy", acc))
subset = sample(dim(iris)[1], size = dim(iris)[1] * 0.8, replace = F)
data.iris = iris
iris.species = c('setosa', 'versicolor', 'virginica')
data.iris = cbind(data.iris, setosa = as.numeric(iris$Species == iris.species[1]))
data.iris = cbind(data.iris, versicolor = as.numeric(iris$Species == iris.species[2]))
data.iris = cbind(data.iris, virginica = as.numeric(iris$Species == iris.species[3]))
data.iris.train = data.iris[subset,]
data.iris.test = data.iris[-subset,]
myNNet = newff(n.neurons = c(4,20,3), learning.rate.global = 0.4, momentum.global = 0.2,
error.criterium = "LMS", Stao=NA, hidden.layer = "sigmoid", output.layer = "sigmoid")
# Train
myNNetModel = train(myNNet, data.iris.train[,1:4], data.iris.train[,6:8], report=F, n.shows = 100, show.step = 100)
# Test
scores = sim.MLPnet(myNNetModel$net, data.iris.test[,1:4])
res = table(max.col(scores), max.col(data.iris.test[,6:8]))
row.names(res) = iris.species
colnames(res) = iris.species
acc = sum(diag(res)) / dim(data.iris.test)[1]
print (paste("zad2:", "accuracy", acc))
subset = sample(dim(iris)[1], size = dim(iris)[1] * 0.8, replace = F)
data.iris = iris
iris.species = c('setosa', 'versicolor', 'virginica')
data.iris = cbind(data.iris, setosa = as.numeric(iris$Species == iris.species[1]))
data.iris = cbind(data.iris, versicolor = as.numeric(iris$Species == iris.species[2]))
data.iris = cbind(data.iris, virginica = as.numeric(iris$Species == iris.species[3]))
data.iris.train = data.iris[subset,]
data.iris.test = data.iris[-subset,]
myNNet = newff(n.neurons = c(4,20,3), learning.rate.global = 0.3, momentum.global = 0.2,
error.criterium = "LMS", Stao=NA, hidden.layer = "sigmoid", output.layer = "sigmoid")
# Train
myNNetModel = train(myNNet, data.iris.train[,1:4], data.iris.train[,6:8], report=F, n.shows = 100, show.step = 100)
# Test
scores = sim.MLPnet(myNNetModel$net, data.iris.test[,1:4])
res = table(max.col(scores), max.col(data.iris.test[,6:8]))
row.names(res) = iris.species
colnames(res) = iris.species
acc = sum(diag(res)) / dim(data.iris.test)[1]
print (paste("zad2:", "accuracy", acc))
subset = sample(dim(iris)[1], size = dim(iris)[1] * 0.8, replace = F)
data.iris = iris
iris.species = c('setosa', 'versicolor', 'virginica')
data.iris = cbind(data.iris, setosa = as.numeric(iris$Species == iris.species[1]))
data.iris = cbind(data.iris, versicolor = as.numeric(iris$Species == iris.species[2]))
data.iris = cbind(data.iris, virginica = as.numeric(iris$Species == iris.species[3]))
data.iris.train = data.iris[subset,]
data.iris.test = data.iris[-subset,]
myNNet = newff(n.neurons = c(4,20,3), learning.rate.global = 0.3, momentum.global = 0.2,
error.criterium = "LMS", Stao=NA, hidden.layer = "sigmoid", output.layer = "sigmoid")
# Train
myNNetModel = train(myNNet, data.iris.train[,1:4], data.iris.train[,6:8], report=F, n.shows = 100, show.step = 100)
# Test
scores = sim.MLPnet(myNNetModel$net, data.iris.test[,1:4])
res = table(max.col(scores), max.col(data.iris.test[,6:8]))
row.names(res) = iris.species
colnames(res) = iris.species
acc = sum(diag(res)) / dim(data.iris.test)[1]
print (paste("zad2:", "accuracy", acc))
source('~/Documents/studia/sus/sus/lab6.R')
install.packages("~/Documents/studia/sus/sus/svm_light.tar", repos = NULL)
as.numeric(max(scores) == max(target))
scores
source('~/Documents/studia/sus/sus/lab6.R')
source('~/Documents/studia/sus/sus/lab6.R')
scores
max.col(scores
)
View(data.iris)
# zad2
subset = sample(dim(iris)[1], size = dim(iris)[1] * 0.8, replace = F)
data.iris = iris
iris.species = c('setosa', 'versicolor', 'virginica')
data.iris = cbind(data.iris, setosa = as.numeric(iris$Species == iris.species[1]))
data.iris = cbind(data.iris, versicolor = as.numeric(iris$Species == iris.species[2]))
data.iris = cbind(data.iris, virginica = as.numeric(iris$Species == iris.species[3]))
data.iris.train = data.iris[subset,]
data.iris.test = data.iris[-subset,]
myNNet = newff(n.neurons = c(4,20,3), learning.rate.global = 0.3, momentum.global = 0.2,
error.criterium = "LMS", Stao=NA, hidden.layer = "sigmoid", output.layer = "sigmoid")
# Train
myNNetModel = train(myNNet, data.iris.train[,1:4], data.iris.train[,6:8], report=F, n.shows = 100, show.step = 100)
# Test
scores = sim.MLPnet(myNNetModel$net, data.iris.test[,1:4])
res = table(max.col(scores), max.col(data.iris.test[,6:8]))
row.names(res) = iris.species
colnames(res) = iris.species
acc = sum(diag(res)) / dim(data.iris.test)[1]
print (paste("zad2:", "accuracy", acc))
subset = sample(dim(iris)[1], size = dim(iris)[1] * 0.8, replace = F)
data.iris = iris
iris.species = c('setosa', 'versicolor', 'virginica')
data.iris = cbind(data.iris, setosa = as.numeric(iris$Species == iris.species[1]))
data.iris = cbind(data.iris, versicolor = as.numeric(iris$Species == iris.species[2]))
data.iris = cbind(data.iris, virginica = as.numeric(iris$Species == iris.species[3]))
data.iris.train = data.iris[subset,]
data.iris.test = data.iris[-subset,]
myNNet = newff(n.neurons = c(4,20,3), learning.rate.global = 0.3, momentum.global = 0.2,
error.criterium = "LMS", Stao=NA, hidden.layer = "sigmoid", output.layer = "sigmoid")
# Train
myNNetModel = train(myNNet, data.iris.train[,1:4], data.iris.train[,6:8], report=F, n.shows = 100, show.step = 100)
# Test
scores = sim.MLPnet(myNNetModel$net, data.iris.test[,1:4])
res = table(max.col(scores), max.col(data.iris.test[,6:8]))
row.names(res) = iris.species
colnames(res) = iris.species
acc = sum(diag(res)) / dim(data.iris.test)[1]
print (paste("zad2:", "accuracy", acc))
res
install.packages("proxy")
?proxy::dist
library(proxy)
library(proxy)
?proxy::dist
summary(pr_DB)
?pr_DB
library(proxy)
?proxy::dist
source('~/Documents/studia/sus/sus/adaboost_zad1.R')
source('~/Documents/studia/sus/sus/adaboost_zad2.R')
source('~/Documents/studia/sus/sus/adaboost_zad1.R')
source('~/Documents/studia/sus/sus/adaboost_zad2.R')
source('~/Documents/studia/sus/sus/adaboost_zad2.R')
source('~/Documents/studia/sus/sus/adaboost_zad2.R')
source('~/Documents/studia/sus/sus/adaboost_zad2.R')
?knn
library(class)
?knn
library(xgboost)
?xgboost
require(xgboost)
library(xgboost)
# Read data as characters to avoid problems connected with factors
train = read.table("letter-recognition-train.csv", header=T, sep=",", colClasses=rep('character', 16))
test = read.table("letter-recognition-test-without-decisions.csv", header=T, sep=",", colClasses=rep('character', 15))
# Convert letters to numbers
train$letter = apply(train, 1, function(r) {which(LETTERS == r[16])})
# Predict value for '?' in every column
predictMissingValues <- function(data, flag) {
for (i in c(6:15)) {
print (paste("Predicting missing values for column ", i, sep=""))
# We use 1-5 columns (there are no '?') and letter column (if possible) to predict missing values.
if (flag) {
test.attr = data[data[i] == '?',c(1:5, 16)]
train.attr = data[data[i] != '?',c(1:5, 16)]
} else {
test.attr = data[data[i] == '?',c(1:5)]
train.attr = data[data[i] != '?',c(1:5)]
}
train.attr.label = as.numeric(data[data[i] != '?',i])
train.attr = apply(train.attr, 2, as.numeric)
test.attr = apply(test.attr, 2, as.numeric)
dtrain = xgb.DMatrix(data = train.attr, label = train.attr.label)
bst = xgb.train(data=dtrain, max_depth=6, eta=0.3, nthread=20,
nrounds=30, num_class=max(train.attr.label)+1, objective="multi:softmax")
# XGBoost built-in crossvalidation to check accuracy on training set and select the best parameters.
# watchlist = list(train = dtrain)
# bst = xgb.cv(data=dtrain, max_depth=6, eta=0.3, nthread=20, nfold=5,
#                nrounds=30, watchlist=watchlist, num_class=max(train.attr.label)+1, objective="multi:softmax")
data[data[i] == '?',i] = predict(bst, test.attr)
}
return (data)
}
subset = sample(1:nrow(train), round(nrow(train)*0.7))
data.train = train[subset,]
data.test = train[-subset,]
train = predictMissingValues(data.train, T)
test = predictMissingValues(data.test, F)
dtrain = xgb.DMatrix(data = apply(train[,-16], 2, as.numeric), label = train[,16])
watchlist = list(train = dtrain)
# XGBoost built-in crossvalidation to check accuracy on training set and select the best parameters.
#bst = xgb.cv(data=dtrain, max_depth=50, eta=0.1, nthread=20, nfold=5,
#             nrounds=50, watchlist=watchlist, num_class=27, objective="multi:softmax")
bst = xgb.train(data=dtrain, max_depth=6, eta=0.3, nthread=20,
nrounds=50, watchlist=watchlist, num_class=27, objective="multi:softmax")
sum(diag(table(predict(bst, apply(test[,-16], 2, as.numeric)), test[,16]))) / nrow(test)
setwd("~/Documents/studia/sus/sus/zad3")
source('~/Documents/studia/sus/sus/zad3/run_mk359758.R')
sum(diag(table(predict(bst, apply(test[,-16], 2, as.numeric)), test[,16]))) / nrow(test)
bst = xgb.train(data=dtrain, max_depth=10, eta=0.3, nthread=20,
nrounds=50, watchlist=watchlist, num_class=27, objective="multi:softmax")
sum(diag(table(predict(bst, apply(test[,-16], 2, as.numeric)), test[,16]))) / nrow(test)
source('~/Documents/studia/sus/sus/zad3/run_mk359758.R')
source('~/Documents/studia/sus/sus/zad3/run_mk359758.R')
source('~/Documents/studia/sus/sus/zad3/run_mk359758.R')
source('~/Documents/studia/sus/sus/zad3/run_mk359758.R')
data.train[data.train == '?',]
data.train[data.train == '?',6]
data.train[data.train[6] == '?',6]
data.train[data.train[6] == '?',]
source('~/Documents/studia/sus/sus/zad3/run_mk359758.R')
View(test)
source('~/Documents/studia/sus/sus/zad3/run_mk359758.R')
sum(diag(table(predict(bst, apply(data.test[,-16], 2, as.numeric)), data.test[,16]))) / nrow(data.test)
source('~/Documents/studia/sus/sus/zad3/run_mk359758.R')
sum(diag(table(predict(bst, apply(data.test[,-16], 2, as.numeric)), data.test[,16]))) / nrow(data.test)
source('~/Documents/studia/sus/sus/zad3/run_mk359758.R')
source('~/Documents/studia/sus/sus/zad3/run_mk359758.R')
source('~/Documents/studia/sus/sus/zad3/run_mk359758.R')
source('~/Documents/studia/sus/sus/zad3/run_mk359758.R')
dtrain = xgb.DMatrix(data = apply(data.train[,-16], 2, as.numeric), label = data.train[,16])
watchlist = list(train = dtrain)
bst = xgb.train(data=dtrain, max_depth=6, eta=0.3, nthread=20,
nrounds=50, watchlist=watchlist, num_class=27, objective="multi:softmax")
bst = xgb.train(data=dtrain, max_depth=6, eta=0.3, nthread=20,
nrounds=50, watchlist=watchlist, num_class=27, objective="multi:softmax")
print(sum(diag(table(predict(bst, apply(data.test[,-16], 2, as.numeric)), data.test[,16]))) / nrow(data.test))
for (i in c(8,9,12,15)) {
data.train[data.train[i] == '?', i] = 0
data.test[data.test[i] == '?', i] = 0
}
b
bst = xgb.train(data=dtrain, max_depth=6, eta=0.3, nthread=20,
nrounds=50, watchlist=watchlist, num_class=27, objective="multi:softmax")
print(sum(diag(table(predict(bst, apply(data.test[,-16], 2, as.numeric)), data.test[,16]))) / nrow(data.test))
