library("Measure", lib.loc="/Library/Frameworks/R.framework/Versions/3.3/Resources/library")
remove.packages("Measure")
load (file = "/Users/mateuszkiebala/Documents/studia/zpp/svm/svm_total.RData")
tpr.res = vector(length = dim(data.test)[1])
tnr.res = vector(length = dim(data.test)[1])
fpr.res = vector(length = dim(data.test)[1])
fnr.res = vector(length = dim(data.test)[1])
precision.res = vector(length = dim(data.test)[1])
accuracy.res = vector(length = dim(data.test)[1])
for (i in (1:dim(data.test)[1])) {
m = MEASURE$new(target = y.test[,i], prediction = svm.res[i,])
threshold = 0.625
tpr.res[i] <- m$truePositiveRate(threshold)
tnr.res[i] <- m$trueNegativeRate(threshold)
fpr.res[i] <- m$falsePositiveRate(threshold)
fnr.res[i] <- m$falseNegativeRate(threshold)
precision.res[i] <- m$precision(threshold)
accuracy.res[i] <- m$accuracy(threshold)
}
print (summary(tpr.res))
print (summary(tnr.res))
print (summary(fpr.res))
print (summary(fnr.res))
print (summary(precision.res))
print (summary(accuracy.res))
library(Measure)
tpr.res = vector(length = dim(data.test)[1])
tnr.res = vector(length = dim(data.test)[1])
fpr.res = vector(length = dim(data.test)[1])
fnr.res = vector(length = dim(data.test)[1])
precision.res = vector(length = dim(data.test)[1])
accuracy.res = vector(length = dim(data.test)[1])
for (i in (1:dim(data.test)[1])) {
m = MEASURE$new(target = y.test[,i], prediction = svm.res[i,])
threshold = 0.625
tpr.res[i] <- m$truePositiveRate(threshold)
tnr.res[i] <- m$trueNegativeRate(threshold)
fpr.res[i] <- m$falsePositiveRate(threshold)
fnr.res[i] <- m$falseNegativeRate(threshold)
precision.res[i] <- m$precision(threshold)
accuracy.res[i] <- m$accuracy(threshold)
}
print (summary(tpr.res))
print (summary(tnr.res))
print (summary(fpr.res))
print (summary(fnr.res))
print (summary(precision.res))
print (summary(accuracy.res))
tpr.res = vector(length = dim(data.test)[1])
tnr.res = vector(length = dim(data.test)[1])
fpr.res = vector(length = dim(data.test)[1])
fnr.res = vector(length = dim(data.test)[1])
precision.res = vector(length = dim(data.test)[1])
accuracy.res = vector(length = dim(data.test)[1])
for (i in (1:dim(data.test)[1])) {
m = MEASURE$new(target = y.test[,i], prediction = svm.res[i,])
print (target)
print (prediction)
threshold = 0.625
tpr.res[i] <- m$truePositiveRate(threshold)
tnr.res[i] <- m$trueNegativeRate(threshold)
fpr.res[i] <- m$falsePositiveRate(threshold)
fnr.res[i] <- m$falseNegativeRate(threshold)
precision.res[i] <- m$precision(threshold)
accuracy.res[i] <- m$accuracy(threshold)
}
tpr.res = vector(length = dim(data.test)[1])
tnr.res = vector(length = dim(data.test)[1])
fpr.res = vector(length = dim(data.test)[1])
fnr.res = vector(length = dim(data.test)[1])
precision.res = vector(length = dim(data.test)[1])
accuracy.res = vector(length = dim(data.test)[1])
for (i in (1:dim(data.test)[1])) {
m = MEASURE$new(target <- y.test[,i], prediction <- svm.res[i,])
print (target)
print (prediction)
threshold = 0.625
tpr.res[i] <- m$truePositiveRate(threshold)
tnr.res[i] <- m$trueNegativeRate(threshold)
fpr.res[i] <- m$falsePositiveRate(threshold)
fnr.res[i] <- m$falseNegativeRate(threshold)
precision.res[i] <- m$precision(threshold)
accuracy.res[i] <- m$accuracy(threshold)
}
tpr.res = vector(length = dim(data.test)[1])
tnr.res = vector(length = dim(data.test)[1])
fpr.res = vector(length = dim(data.test)[1])
fnr.res = vector(length = dim(data.test)[1])
precision.res = vector(length = dim(data.test)[1])
accuracy.res = vector(length = dim(data.test)[1])
for (i in (1:dim(data.test)[1])) {
m = MEASURE$new(target <- y.test[,i], prediction <- svm.res[i,])
print (target)
print (as.numeric(prediction))
threshold = 0.625
tpr.res[i] <- m$truePositiveRate(threshold)
tnr.res[i] <- m$trueNegativeRate(threshold)
fpr.res[i] <- m$falsePositiveRate(threshold)
fnr.res[i] <- m$falseNegativeRate(threshold)
precision.res[i] <- m$precision(threshold)
accuracy.res[i] <- m$accuracy(threshold)
}
tpr.res = vector(length = dim(data.test)[1])
tnr.res = vector(length = dim(data.test)[1])
fpr.res = vector(length = dim(data.test)[1])
fnr.res = vector(length = dim(data.test)[1])
precision.res = vector(length = dim(data.test)[1])
accuracy.res = vector(length = dim(data.test)[1])
for (i in (1:dim(data.test)[1])) {
m = MEASURE$new(target <- y.test[,i], prediction <- svm.res[i,])
print (target)
print (round(as.numeric(prediction), 3))
threshold = 0.625
tpr.res[i] <- m$truePositiveRate(threshold)
tnr.res[i] <- m$trueNegativeRate(threshold)
fpr.res[i] <- m$falsePositiveRate(threshold)
fnr.res[i] <- m$falseNegativeRate(threshold)
precision.res[i] <- m$precision(threshold)
accuracy.res[i] <- m$accuracy(threshold)
}
tpr.res = vector(length = dim(data.test)[1])
tnr.res = vector(length = dim(data.test)[1])
fpr.res = vector(length = dim(data.test)[1])
fnr.res = vector(length = dim(data.test)[1])
precision.res = vector(length = dim(data.test)[1])
accuracy.res = vector(length = dim(data.test)[1])
for (i in (1:dim(data.test)[1])) {
m = MEASURE$new(target <- y.test[,i], prediction <- svm.res[i,])
print (data.frame(t = target, p = round(as.numeric(prediction), 3)))
threshold = 0.625
tpr.res[i] <- m$truePositiveRate(threshold)
tnr.res[i] <- m$trueNegativeRate(threshold)
fpr.res[i] <- m$falsePositiveRate(threshold)
fnr.res[i] <- m$falseNegativeRate(threshold)
precision.res[i] <- m$precision(threshold)
accuracy.res[i] <- m$accuracy(threshold)
}
setwd("~/Documents/studia/sus/sus/zad1")
# Author: Mateusz Kiebala 359758
#install.packages("tree")
#install.packages("class")
#install.packages("e1071")
#install.packages("ROCR")
library(tree)
library(class)
library(e1071)
library(ROCR)
set.seed(1234)
data <- read.table(file = "dane.csv", header = TRUE, sep = ",")
data <- data[sample(nrow(data)),]
calculate <- function (n) {
print (n)
sample.size = nrow(data) / n
tree.res = data.frame(auc = vector(length = n))
knn10.res = data.frame(auc = vector(length = n))
knn50.res = data.frame(auc = vector(length = n))
knn100.res = data.frame(auc = vector(length = n))
bayes.res = data.frame(auc = vector(length = n))
for (i in 1:n) {
sample = (((i-1)*sample.size + 1) : (i*sample.size))
data.train = data[-sample,]
data.test = data[sample,]
# Decision tree
treeModel = tree(as.factor(D)~., data.train)
tree.prediction = predict(treeModel, data.test, type='class')
preds = prediction(as.numeric(tree.prediction) - 1, data.test$D)
tree.res$auc[i] = slot(performance(preds, measure="auc"), "y.values")
# KNN k = 10
knn10.prediction = knn(data.train[,1:10], data.test[,1:10], data.train$D, k=10)
preds = prediction(as.numeric(knn10.prediction) - 1, data.test$D)
knn10.res$auc[i] = slot(performance(preds, measure="auc"), "y.values")
# KNN k = 50
knn50.prediction = knn(data.train[,1:10], data.test[,1:10], data.train$D, k=50)
preds = prediction(as.numeric(knn50.prediction) - 1, data.test$D)
knn50.res$auc[i] = slot(performance(preds, measure="auc"), "y.values")
# KNN k = 100
knn100.prediction = knn(data.train[,1:10], data.test[,1:10], data.train$D, k=100)
preds = prediction(as.numeric(knn100.prediction) - 1, data.test$D)
knn100.res$auc[i] = slot(performance(preds, measure="auc"), "y.values")
# Naive Bayes
naiveBayesModel = naiveBayes(as.factor(D)~., data.train)
bayes.prediction = predict(naiveBayesModel, data.test, type="class")
preds = prediction(as.numeric(bayes.prediction) - 1, data.test$D)
bayes.res$auc[i] = slot(performance(preds, measure="auc"), "y.values")
}
c(mean(as.numeric(tree.res$auc)),
mean(as.numeric(knn10.res$auc)),
mean(as.numeric(knn50.res$auc)),
mean(as.numeric(knn100.res$auc)),
mean(as.numeric(bayes.res$auc)))
}
# znormalizowac dane
# wykres ROC
res <- sapply(c(2,4,8,10,16,20,25,32,40,50,100,200), calculate)
print ("Decision tree auc summary:")
print (summary(res[1,]))
print ("KNN (k=10) auc summary:")
print (summary(res[2,]))
print ("KNN (k=50) auc summary:")
print (summary(res[3,]))
print ("KNN (k=100) auc summary:")
print (summary(res[4,]))
print ("Naive Bayes auc summary:")
print (summary(res[5,]))
